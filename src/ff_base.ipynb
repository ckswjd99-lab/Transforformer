{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Forward-Forward Models\n",
    "\n",
    "Codes mainly referenced from: https://github.com/carloalbertobarbano/forward-forward-pytorch\n",
    "\n",
    "1. Training base FF model, presented in paper: https://arxiv.org/abs/2212.13345\n",
    "\n",
    "2. Training modified FF model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cjpark/anaconda3/envs/DL/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import forward_forward as ff\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import argparse\n",
    "import torch.utils.tensorboard\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERPARAMS ##\n",
    "\n",
    "HARD_NEGATIVES = True\n",
    "LAYER_SIZE = 2000\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 0\n",
    "NUM_EPOCHS = 60\n",
    "STEPS_PER_BLOCK = 60\n",
    "THETA = 10.\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UTILS ##\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(1.0 / batch_size).item())\n",
    "        return res\n",
    "\n",
    "def norm_y(y_one_hot: torch.Tensor):\n",
    "    return y_one_hot.sub(0.1307).div(0.3081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING ##\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(network_ff, linear_cf, test_loader, verbose=False):\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "\n",
    "    for (x_test, y_test) in test_loader:\n",
    "        x_test, y_test = x_test.to(DEVICE), y_test.to(DEVICE)\n",
    "        x_test = x_test.view(x_test.shape[0], -1)\n",
    "\n",
    "        acts_for_labels = []\n",
    "\n",
    "        # slow method\n",
    "        for label in range(10):\n",
    "            test_label = torch.ones_like(y_test).fill_(label)\n",
    "            test_label = norm_y(F.one_hot(test_label, num_classes=10))\n",
    "            x_with_labels = torch.cat((x_test, test_label), dim=1)\n",
    "            \n",
    "            acts = network_ff(x_with_labels)\n",
    "            acts = acts.norm(dim=-1)\n",
    "            acts_for_labels.append(acts)\n",
    "        \n",
    "        # these are logits\n",
    "        acts_for_labels = torch.stack(acts_for_labels, dim=1) #should be BSZxLABELSxLAYERS (10)\n",
    "        all_outputs.append(acts_for_labels)\n",
    "        all_labels.append(y_test)\n",
    "\n",
    "        # quick method\n",
    "        neutral_label = norm_y(torch.full((x_test.shape[0], 10), 0.1, device=DEVICE))\n",
    "        acts = network_ff(torch.cat((x_test, neutral_label), dim=1))\n",
    "        acts = acts[:, 1:]\n",
    "        logits = linear_cf(acts.view(acts.shape[0], -1))\n",
    "        all_logits.append(logits)\n",
    "\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_logits = torch.cat(all_logits)\n",
    "\n",
    "    slow_acc = accuracy(all_outputs.mean(dim=-1), all_labels, topk=(1,))[0]\n",
    "    fast_acc = accuracy(all_logits, all_labels, topk=(1,))[0]\n",
    "    return slow_acc, fast_acc\n",
    "\n",
    "def train(network_ff, optimizer, linear_cf, optimizer_cf, train_loader, start_block):\n",
    "    running_loss = 0.\n",
    "    running_ce = 0.\n",
    "\n",
    "    for (x, y_pos) in train_loader:\n",
    "        x, y_pos = x.to(DEVICE), y_pos.to(DEVICE)\n",
    "        x = x.view(BATCH_SIZE, -1)\n",
    "\n",
    "        # positive pairs\n",
    "        y_pos_one_hot = norm_y(F.one_hot(y_pos, num_classes=10))\n",
    "        x_pos = torch.cat((x, y_pos_one_hot), dim=1)\n",
    "        \n",
    "        # sample negatives (and train linear cf)\n",
    "        with torch.no_grad():\n",
    "            ys = network_ff(torch.cat((x, torch.ones_like(y_pos_one_hot).fill_(0.1)), dim=1))\n",
    "            # first layer should be excluded!\n",
    "            ys = ys[:, 1:]\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            logits = linear_cf(ys.view(ys.shape[0], -1).detach())\n",
    "            ce = F.cross_entropy(logits, y_pos)\n",
    "            ce.backward()\n",
    "            running_ce += ce.detach()\n",
    "\n",
    "        optimizer_cf.step()\n",
    "        optimizer_cf.zero_grad()\n",
    "\n",
    "        # negative pairs from softmax layer\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        idx = torch.where(preds != y_pos)\n",
    "        y_hard_one_hot = norm_y(F.one_hot(preds, num_classes=10))\n",
    "        x_hard = torch.cat((x, y_hard_one_hot), dim=1)[idx]\n",
    "\n",
    "        # negative pairs from random labels\n",
    "        y_rand = torch.randint(0, 10, (BATCH_SIZE,), device=DEVICE)\n",
    "        idx = torch.where(y_rand != y_pos) # correct labels\n",
    "        y_rand_one_hot = norm_y(F.one_hot(y_rand, num_classes=10))\n",
    "        x_rand = torch.cat((x, y_rand_one_hot), dim=1) #[idx] # keeping positives seems to work better\n",
    "\n",
    "        x_neg = x_rand\n",
    "        if HARD_NEGATIVES:\n",
    "            x_neg = torch.cat((x_neg, x_hard), dim=0)\n",
    "            \n",
    "        with torch.enable_grad():\n",
    "            z_pos = network_ff(x_pos, cat=False)\n",
    "            z_neg = network_ff(x_neg, cat=False)\n",
    "\n",
    "            for idx, (zp, zn) in enumerate(zip(z_pos, z_neg)):\n",
    "                if idx < start_block:\n",
    "                    continue\n",
    "\n",
    "                positive_loss = torch.log(1 + torch.exp((-zp.norm(dim=-1) + THETA))).mean()\n",
    "                negative_loss = torch.log(1 + torch.exp((zn.norm(dim=-1) - THETA))).mean()\n",
    "                loss = positive_loss + negative_loss\n",
    "                loss.backward()\n",
    "\n",
    "                running_loss += loss.detach()\n",
    "                optimizer[idx].step()\n",
    "                optimizer[idx].zero_grad()\n",
    "    \n",
    "    running_loss /= len(train_loader)\n",
    "    running_ce /= len(train_loader)\n",
    "\n",
    "    return running_loss, running_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFBase(\n",
      "  (blocks): Sequential(\n",
      "    (0): BlockBase(\n",
      "      (fc): Linear(in_features=794, out_features=2000, bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BlockBase(\n",
      "      (fc): Linear(in_features=2000, out_features=2000, bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BlockBase(\n",
      "      (fc): Linear(in_features=2000, out_features=2000, bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BlockBase(\n",
      "      (fc): Linear(in_features=2000, out_features=2000, bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## PREPARE ##\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "T_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "T_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MNIST(\"~/data\", train=True, download=True, transform=T_train), \n",
    "    batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=8,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    MNIST(\"~/data\", train=False, download=True, transform=T_test), \n",
    "    batch_size=BATCH_SIZE, shuffle=True, num_workers=8,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "size = LAYER_SIZE\n",
    "network_ff = ff.FFBase(dims=[28*28 + 10, size, size, size, size]).to(DEVICE)\n",
    "print(network_ff)\n",
    "\n",
    "# Create one optimizer for evey relu layer (block)\n",
    "optimizers = [\n",
    "    torch.optim.Adam(block.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        for block in network_ff.blocks.children()\n",
    "] \n",
    "\n",
    "# Softmax layer for predicting classes from embeddings (fast method)\n",
    "linear_cf = nn.Linear(size*(network_ff.n_blocks-1), 10).to(DEVICE)\n",
    "optimizer_cf = torch.optim.Adam(linear_cf.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train Base Model\n",
    "\n",
    "Train base model from paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n",
      "torch.Size([200, 3, 2000])\n"
     ]
    }
   ],
   "source": [
    "## RUN ##\n",
    "\n",
    "writer = SummaryWriter()\n",
    "start_block = 0\n",
    "\n",
    "max_fast_acc = 0\n",
    "max_fast_acc_epoch = 0\n",
    "max_slow_acc = 0\n",
    "max_slow_acc_epoch = 0\n",
    "\n",
    "pbar = tqdm(range(1, NUM_EPOCHS+1), total=NUM_EPOCHS)\n",
    "\n",
    "for step in pbar:\n",
    "    running_loss, running_ce = train(network_ff, optimizers, linear_cf, optimizer_cf,\n",
    "                                        train_loader, start_block)\n",
    "    if step % STEPS_PER_BLOCK == 0:\n",
    "        if start_block+1 < network_ff.n_blocks:\n",
    "            start_block += 1\n",
    "            print(\"Freezing block\", start_block-1)\n",
    "    \n",
    "    writer.add_scalar(\"train/loss\", running_loss, step)\n",
    "    writer.add_scalar(\"train/ce\", running_ce, step)\n",
    "\n",
    "    train_slow_acc, train_fast_acc = test(network_ff, linear_cf, train_loader)\n",
    "    test_slow_acc, test_fast_acc = test(network_ff, linear_cf, test_loader)\n",
    "\n",
    "    writer.add_scalar(\"acc_fast/train\", train_fast_acc, step)\n",
    "    writer.add_scalar(\"acc_fast/test\", test_fast_acc, step)\n",
    "    writer.add_scalar(\"acc_slow/train\", train_slow_acc, step)\n",
    "    writer.add_scalar(\"acc_slow/test\", test_slow_acc, step)\n",
    "\n",
    "    pbar.set_postfix({\n",
    "        \"train_fast_acc\": train_fast_acc,\n",
    "        \"train_slow_acc\": train_slow_acc,\n",
    "        \"test_fast_acc\": test_fast_acc,\n",
    "        \"test_slow_acc\": test_slow_acc\n",
    "    })\n",
    "\n",
    "    if test_fast_acc > max_fast_acc:\n",
    "        max_fast_acc = test_fast_acc\n",
    "        max_fast_acc_epoch = step\n",
    "    \n",
    "    if test_slow_acc > max_slow_acc:\n",
    "        max_slow_acc = test_slow_acc\n",
    "        max_slow_acc_epoch = step\n",
    "\n",
    "print(\"Min fast acc:\", max_fast_acc, \"at epoch\", max_fast_acc_epoch)\n",
    "print(\"Min slow acc:\", max_slow_acc, \"at epoch\", max_slow_acc_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Custom Model\n",
    "\n",
    "Train MLP-Blocked FF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = LAYER_SIZE\n",
    "ff_MLP = ff.FFMLP(dims=[28*28 + 10, size, size, size]).to(DEVICE)\n",
    "print(ff_MLP)\n",
    "\n",
    "# Create one optimizer for evey relu layer (block)\n",
    "optimizers = [\n",
    "    torch.optim.Adam(block.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        for block in network_ff.blocks.children()\n",
    "] \n",
    "\n",
    "# Softmax layer for predicting classes from embeddings (fast method)\n",
    "linear_MLP_cf = nn.Linear(size*(ff_MLP.n_blocks-1), 10).to(DEVICE)\n",
    "optimizer_MLP_cf = torch.optim.Adam(linear_MLP_cf.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN ##\n",
    "\n",
    "writer = SummaryWriter()\n",
    "start_block = 0\n",
    "\n",
    "max_fast_acc = 0\n",
    "max_fast_acc_epoch = 0\n",
    "max_slow_acc = 0\n",
    "max_slow_acc_epoch = 0\n",
    "\n",
    "pbar = tqdm(range(1, NUM_EPOCHS+1), total=NUM_EPOCHS)\n",
    "\n",
    "for step in pbar:\n",
    "    running_loss, running_ce = train(ff_MLP, optimizers, linear_MLP_cf, optimizer_MLP_cf,\n",
    "                                        train_loader, start_block)\n",
    "    if step % STEPS_PER_BLOCK == 0:\n",
    "        if start_block+1 < ff_MLP.n_blocks:\n",
    "            start_block += 1\n",
    "            print(\"Freezing block\", start_block-1)\n",
    "    \n",
    "    writer.add_scalar(\"train/loss\", running_loss, step)\n",
    "    writer.add_scalar(\"train/ce\", running_ce, step)\n",
    "\n",
    "    train_slow_acc, train_fast_acc = test(ff_MLP, linear_MLP_cf, train_loader)\n",
    "    test_slow_acc, test_fast_acc = test(ff_MLP, linear_MLP_cf, test_loader)\n",
    "\n",
    "    writer.add_scalar(\"acc_fast/train\", train_fast_acc, step)\n",
    "    writer.add_scalar(\"acc_fast/test\", test_fast_acc, step)\n",
    "    writer.add_scalar(\"acc_slow/train\", train_slow_acc, step)\n",
    "    writer.add_scalar(\"acc_slow/test\", test_slow_acc, step)\n",
    "\n",
    "    pbar.set_postfix({\n",
    "        \"train_fast_acc\": train_fast_acc,\n",
    "        \"train_slow_acc\": train_slow_acc,\n",
    "        \"test_fast_acc\": test_fast_acc,\n",
    "        \"test_slow_acc\": test_slow_acc\n",
    "    })\n",
    "\n",
    "    if test_fast_acc > max_fast_acc:\n",
    "        max_fast_acc = test_fast_acc\n",
    "        max_fast_acc_epoch = step\n",
    "    \n",
    "    if test_slow_acc > max_slow_acc:\n",
    "        max_slow_acc = test_slow_acc\n",
    "        max_slow_acc_epoch = step\n",
    "\n",
    "print(\"Min fast acc:\", max_fast_acc, \"at epoch\", max_fast_acc_epoch)\n",
    "print(\"Min slow acc:\", max_slow_acc, \"at epoch\", max_slow_acc_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
